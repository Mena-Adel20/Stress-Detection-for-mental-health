{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814331c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\otaku7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\otaku7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\otaku7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\otaku7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "## Import required libraries\n",
    "\n",
    "## for data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## for processing\n",
    "import nltk\n",
    "import re\n",
    "import ftfy\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "## WordCloud - Python linrary for creating image wordclouds\n",
    "from wordcloud import WordCloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7b9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\otaku7\\Desktop\\GP\\stress\\Stress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "296f7385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_id</th>\n",
       "      <th>sentence_range</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>social_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>8601tu</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1521614353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>assistance</td>\n",
       "      <td>8lbrx9</td>\n",
       "      <td>(0, 5)</td>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1527009817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9ch1zh</td>\n",
       "      <td>(15, 20)</td>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1535935605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7rorpp</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1516429555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>survivorsofabuse</td>\n",
       "      <td>9p2gbc</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1539809005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>relationships</td>\n",
       "      <td>7oee1t</td>\n",
       "      <td>[35, 40]</td>\n",
       "      <td>* Her, a week ago: Precious, how are you? (I i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1515187044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>9p4ung</td>\n",
       "      <td>[20, 25]</td>\n",
       "      <td>I don't have the ability to cope with it anymo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1539827412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>anxiety</td>\n",
       "      <td>9nam6l</td>\n",
       "      <td>(5, 10)</td>\n",
       "      <td>In case this is the first time you're reading ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1539269312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>almosthomeless</td>\n",
       "      <td>5y53ya</td>\n",
       "      <td>[5, 10]</td>\n",
       "      <td>Do you find this normal? They have a good rela...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1488938143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>ptsd</td>\n",
       "      <td>5y25cl</td>\n",
       "      <td>[0, 5]</td>\n",
       "      <td>I was talking to my mom this morning and she s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1488909516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             subreddit post_id sentence_range  \\\n",
       "0                 ptsd  8601tu       (15, 20)   \n",
       "1           assistance  8lbrx9         (0, 5)   \n",
       "2                 ptsd  9ch1zh       (15, 20)   \n",
       "3        relationships  7rorpp        [5, 10]   \n",
       "4     survivorsofabuse  9p2gbc         [0, 5]   \n",
       "...                ...     ...            ...   \n",
       "2833     relationships  7oee1t       [35, 40]   \n",
       "2834              ptsd  9p4ung       [20, 25]   \n",
       "2835           anxiety  9nam6l        (5, 10)   \n",
       "2836    almosthomeless  5y53ya        [5, 10]   \n",
       "2837              ptsd  5y25cl         [0, 5]   \n",
       "\n",
       "                                                   text  label  confidence  \\\n",
       "0     He said he had not felt that way before, sugge...      1    0.800000   \n",
       "1     Hey there r/assistance, Not sure if this is th...      0    1.000000   \n",
       "2     My mom then hit me with the newspaper and it s...      1    0.800000   \n",
       "3     until i met my new boyfriend, he is amazing, h...      1    0.600000   \n",
       "4     October is Domestic Violence Awareness Month a...      1    0.800000   \n",
       "...                                                 ...    ...         ...   \n",
       "2833  * Her, a week ago: Precious, how are you? (I i...      0    1.000000   \n",
       "2834  I don't have the ability to cope with it anymo...      1    1.000000   \n",
       "2835  In case this is the first time you're reading ...      0    1.000000   \n",
       "2836  Do you find this normal? They have a good rela...      0    0.571429   \n",
       "2837  I was talking to my mom this morning and she s...      1    0.571429   \n",
       "\n",
       "      social_timestamp  \n",
       "0           1521614353  \n",
       "1           1527009817  \n",
       "2           1535935605  \n",
       "3           1516429555  \n",
       "4           1539809005  \n",
       "...                ...  \n",
       "2833        1515187044  \n",
       "2834        1539827412  \n",
       "2835        1539269312  \n",
       "2836        1488938143  \n",
       "2837        1488909516  \n",
       "\n",
       "[2838 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe629e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['subreddit','post_id','sentence_range','confidence','social_timestamp'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31bfb164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>* Her, a week ago: Precious, how are you? (I i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>I don't have the ability to cope with it anymo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>In case this is the first time you're reading ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>Do you find this normal? They have a good rela...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>I was talking to my mom this morning and she s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     He said he had not felt that way before, sugge...      1\n",
       "1     Hey there r/assistance, Not sure if this is th...      0\n",
       "2     My mom then hit me with the newspaper and it s...      1\n",
       "3     until i met my new boyfriend, he is amazing, h...      1\n",
       "4     October is Domestic Violence Awareness Month a...      1\n",
       "...                                                 ...    ...\n",
       "2833  * Her, a week ago: Precious, how are you? (I i...      0\n",
       "2834  I don't have the ability to cope with it anymo...      1\n",
       "2835  In case this is the first time you're reading ...      0\n",
       "2836  Do you find this normal? They have a good rela...      0\n",
       "2837  I was talking to my mom this morning and she s...      1\n",
       "\n",
       "[2838 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73b047d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand Contraction\n",
    "cList = {\n",
    "  \"ain't\": \"am not\",\n",
    "  \"aren't\": \"are not\",\n",
    "  \"can't\": \"cannot\",\n",
    "  \"can't've\": \"cannot have\",\n",
    "  \"'cause\": \"because\",\n",
    "  \"could've\": \"could have\",\n",
    "  \"couldn't\": \"could not\",\n",
    "  \"couldn't've\": \"could not have\",\n",
    "  \"didn't\": \"did not\",\n",
    "  \"doesn't\": \"does not\",\n",
    "  \"don't\": \"do not\",\n",
    "  \"hadn't\": \"had not\",\n",
    "  \"hadn't've\": \"had not have\",\n",
    "  \"hasn't\": \"has not\",\n",
    "  \"haven't\": \"have not\",\n",
    "  \"he'd\": \"he would\",\n",
    "  \"he'd've\": \"he would have\",\n",
    "  \"he'll\": \"he will\",\n",
    "  \"he'll've\": \"he will have\",\n",
    "  \"he's\": \"he is\",\n",
    "  \"how'd\": \"how did\",\n",
    "  \"how'd'y\": \"how do you\",\n",
    "  \"how'll\": \"how will\",\n",
    "  \"how's\": \"how is\",\n",
    "  \"I'd\": \"I would\",\n",
    "  \"I'd've\": \"I would have\",\n",
    "  \"I'll\": \"I will\",\n",
    "  \"I'll've\": \"I will have\",\n",
    "  \"I'm\": \"I am\",\n",
    "  \"I've\": \"I have\",\n",
    "  \"isn't\": \"is not\",\n",
    "  \"it'd\": \"it had\",\n",
    "  \"it'd've\": \"it would have\",\n",
    "  \"it'll\": \"it will\",\n",
    "  \"it'll've\": \"it will have\",\n",
    "  \"it's\": \"it is\",\n",
    "  \"let's\": \"let us\",\n",
    "  \"ma'am\": \"madam\",\n",
    "  \"mayn't\": \"may not\",\n",
    "  \"might've\": \"might have\",\n",
    "  \"mightn't\": \"might not\",\n",
    "  \"mightn't've\": \"might not have\",\n",
    "  \"must've\": \"must have\",\n",
    "  \"mustn't\": \"must not\",\n",
    "  \"mustn't've\": \"must not have\",\n",
    "  \"needn't\": \"need not\",\n",
    "  \"needn't've\": \"need not have\",\n",
    "  \"o'clock\": \"of the clock\",\n",
    "  \"oughtn't\": \"ought not\",\n",
    "  \"oughtn't've\": \"ought not have\",\n",
    "  \"shan't\": \"shall not\",\n",
    "  \"sha'n't\": \"shall not\",\n",
    "  \"shan't've\": \"shall not have\",\n",
    "  \"she'd\": \"she would\",\n",
    "  \"she'd've\": \"she would have\",\n",
    "  \"she'll\": \"she will\",\n",
    "  \"she'll've\": \"she will have\",\n",
    "  \"she's\": \"she is\",\n",
    "  \"should've\": \"should have\",\n",
    "  \"shouldn't\": \"should not\",\n",
    "  \"shouldn't've\": \"should not have\",\n",
    "  \"so've\": \"so have\",\n",
    "  \"so's\": \"so is\",\n",
    "  \"that'd\": \"that would\",\n",
    "  \"that'd've\": \"that would have\",\n",
    "  \"that's\": \"that is\",\n",
    "  \"there'd\": \"there had\",\n",
    "  \"there'd've\": \"there would have\",\n",
    "  \"there's\": \"there is\",\n",
    "  \"they'd\": \"they would\",\n",
    "  \"they'd've\": \"they would have\",\n",
    "  \"they'll\": \"they will\",\n",
    "  \"they'll've\": \"they will have\",\n",
    "  \"they're\": \"they are\",\n",
    "  \"they've\": \"they have\",\n",
    "  \"to've\": \"to have\",\n",
    "  \"wasn't\": \"was not\",\n",
    "  \"we'd\": \"we had\",\n",
    "  \"we'd've\": \"we would have\",\n",
    "  \"we'll\": \"we will\",\n",
    "  \"we'll've\": \"we will have\",\n",
    "  \"we're\": \"we are\",\n",
    "  \"we've\": \"we have\",\n",
    "  \"weren't\": \"were not\",\n",
    "  \"what'll\": \"what will\",\n",
    "  \"what'll've\": \"what will have\",\n",
    "  \"what're\": \"what are\",\n",
    "  \"what's\": \"what is\",\n",
    "  \"what've\": \"what have\",\n",
    "  \"when's\": \"when is\",\n",
    "  \"when've\": \"when have\",\n",
    "  \"where'd\": \"where did\",\n",
    "  \"where's\": \"where is\",\n",
    "  \"where've\": \"where have\",\n",
    "  \"who'll\": \"who will\",\n",
    "  \"who'll've\": \"who will have\",\n",
    "  \"who's\": \"who is\",\n",
    "  \"who've\": \"who have\",\n",
    "  \"why's\": \"why is\",\n",
    "  \"why've\": \"why have\",\n",
    "  \"will've\": \"will have\",\n",
    "  \"won't\": \"will not\",\n",
    "  \"won't've\": \"will not have\",\n",
    "  \"would've\": \"would have\",\n",
    "  \"wouldn't\": \"would not\",\n",
    "  \"wouldn't've\": \"would not have\",\n",
    "  \"y'all\": \"you all\",\n",
    "  \"y'alls\": \"you alls\",\n",
    "  \"y'all'd\": \"you all would\",\n",
    "  \"y'all'd've\": \"you all would have\",\n",
    "  \"y'all're\": \"you all are\",\n",
    "  \"y'all've\": \"you all have\",\n",
    "  \"you'd\": \"you had\",\n",
    "  \"you'd've\": \"you would have\",\n",
    "  \"you'll\": \"you you will\",\n",
    "  \"you'll've\": \"you you will have\",\n",
    "  \"you're\": \"you are\",\n",
    "  \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "c_re = re.compile('(%s)' % '|'.join(cList.keys()))\n",
    "\n",
    "def expandContractions(text, c_re=c_re):\n",
    "    def replace(match):\n",
    "        return cList[match.group(0)]\n",
    "    return c_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "496769c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to perform stepwise cleaning process\n",
    "def tweets_cleaner(tweet):\n",
    "    \n",
    "    cleaned_tweets = []\n",
    "    tweet = tweet.lower() #lowercase\n",
    "    \n",
    "  # if url links then don't append to avoid news articles\n",
    "  # also check tweet length, save those > 5 \n",
    "    if re.match(\"(\\w+:\\/\\/\\S+)\", tweet) == None and len(tweet) > 5:\n",
    "        \n",
    "    \n",
    "    #remove hashtag, @mention, emoji and image URLs\n",
    "        tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(\\#[A-Za-z0-9]+)|(<.>)|(pic\\.twitter\\.com\\/.*)\", \" \", tweet).split())\n",
    "\n",
    "        #fix weirdly encoded texts\n",
    "        tweet = ftfy.fix_text(tweet)\n",
    "\n",
    "        #expand contraction\n",
    "        tweet = expandContractions(tweet)\n",
    "\n",
    "\n",
    "        #remove punctuation\n",
    "        tweet = ' '.join(re.sub(\"([^0-9A-Za-z \\t])\", \" \", tweet).split())\n",
    "\n",
    "        #stop words and lemmatization\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        word_tokens = nltk.word_tokenize(tweet)\n",
    "\n",
    "        lemmatizer=WordNetLemmatizer()\n",
    "        filtered_sentence = [lemmatizer.lemmatize(word) for word in word_tokens if not word in stop_words]\n",
    "        # back to string from list\n",
    "        tweet = ' '.join(filtered_sentence) # join words with a space in between them\n",
    "\n",
    "        cleaned_tweets.append(tweet)\n",
    "\n",
    "    return cleaned_tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a852943b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "64b9bd01",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21860/3470223930.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweets_cleaner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21860/2370134966.py\u001b[0m in \u001b[0;36mtweets_cleaner\u001b[1;34m(tweet)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mcleaned_tweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#lowercase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# if url links then don't append to avoid news articles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "corpus = tweets_cleaner(tweets_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85da1136",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (2834)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21860/923459771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_text'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3611\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3612\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3614\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m         \"\"\"\n\u001b[1;32m-> 3784\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3785\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3786\u001b[0m         if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4508\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4509\u001b[1;33m             \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4510\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \"\"\"\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (0) does not match length of index (2834)"
     ]
    }
   ],
   "source": [
    "df['clean_text'] = corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2d87d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He said he had not felt that way before, sugge...</td>\n",
       "      <td>1</td>\n",
       "      <td>said felt way suggeted go rest trigger ahead y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey r assistance sure right place post go curr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My mom then hit me with the newspaper and it s...</td>\n",
       "      <td>1</td>\n",
       "      <td>mom hit newspaper shocked would know like play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
       "      <td>1</td>\n",
       "      <td>met new boyfriend amazing kind sweet good stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>October is Domestic Violence Awareness Month a...</td>\n",
       "      <td>1</td>\n",
       "      <td>october domestic violence awareness month dome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>* Her, a week ago: Precious, how are you? (I i...</td>\n",
       "      <td>0</td>\n",
       "      <td>week ago precious ignored jan 1 happy year pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2834</th>\n",
       "      <td>I don't have the ability to cope with it anymo...</td>\n",
       "      <td>1</td>\n",
       "      <td>ability cope anymore trying lot thing triggeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2835</th>\n",
       "      <td>In case this is the first time you're reading ...</td>\n",
       "      <td>0</td>\n",
       "      <td>case first time reading post looking people wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2836</th>\n",
       "      <td>Do you find this normal? They have a good rela...</td>\n",
       "      <td>0</td>\n",
       "      <td>find normal good relationship main problem see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2837</th>\n",
       "      <td>I was talking to my mom this morning and she s...</td>\n",
       "      <td>1</td>\n",
       "      <td>talking mom morning said sister trauma worse m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2838 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label  \\\n",
       "0     He said he had not felt that way before, sugge...      1   \n",
       "1     Hey there r/assistance, Not sure if this is th...      0   \n",
       "2     My mom then hit me with the newspaper and it s...      1   \n",
       "3     until i met my new boyfriend, he is amazing, h...      1   \n",
       "4     October is Domestic Violence Awareness Month a...      1   \n",
       "...                                                 ...    ...   \n",
       "2833  * Her, a week ago: Precious, how are you? (I i...      0   \n",
       "2834  I don't have the ability to cope with it anymo...      1   \n",
       "2835  In case this is the first time you're reading ...      0   \n",
       "2836  Do you find this normal? They have a good rela...      0   \n",
       "2837  I was talking to my mom this morning and she s...      1   \n",
       "\n",
       "                                             clean_text  \n",
       "0     said felt way suggeted go rest trigger ahead y...  \n",
       "1     hey r assistance sure right place post go curr...  \n",
       "2     mom hit newspaper shocked would know like play...  \n",
       "3     met new boyfriend amazing kind sweet good stud...  \n",
       "4     october domestic violence awareness month dome...  \n",
       "...                                                 ...  \n",
       "2833  week ago precious ignored jan 1 happy year pre...  \n",
       "2834  ability cope anymore trying lot thing triggeri...  \n",
       "2835  case first time reading post looking people wi...  \n",
       "2836  find normal good relationship main problem see...  \n",
       "2837  talking mom morning said sister trauma worse m...  \n",
       "\n",
       "[2838 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd24aee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# replace field that's entirely space (or empty) with NaN\n",
    "df.replace(r'^\\s*$', np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f1e11339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, label, clean_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['clean_text'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72436fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deleting the rows with nan \n",
    "df.dropna(subset=['clean_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da4150f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Import required libraries\n",
    "\n",
    "## warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## for data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## TF-IDF \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import en_core_web_lg\n",
    "\n",
    "\n",
    "\n",
    "## Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "\n",
    "\n",
    "## Feature selection\n",
    "from sklearn import feature_selection\n",
    "\n",
    "## libraraies for classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "## for saving model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "621e9bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24a8df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = pd.np.array([pd.np.array([token.vector for token in nlp(s)]).mean(axis=0) * pd.np.ones((300)) \\\n",
    "                           for s in df['clean_text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db387d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.23951681,  1.62246275, -0.80913979, ...,  0.36847553,\n",
       "        -1.91384685,  1.71876025],\n",
       "       [ 0.08158433,  0.26458135, -1.94797432, ..., -0.54826713,\n",
       "        -1.81906128,  0.87428159],\n",
       "       [ 0.02348762,  0.83661175, -2.54537821, ...,  1.50473964,\n",
       "        -1.38440704,  1.16022635],\n",
       "       ...,\n",
       "       [ 0.37162542, -0.19524668, -2.11935306, ..., -2.11180496,\n",
       "        -2.5505147 ,  2.75154781],\n",
       "       [ 0.44912869,  1.23822236, -1.86733043, ...,  1.35216367,\n",
       "        -2.65918159,  0.26423931],\n",
       "       [ 1.2982229 ,  0.70283377, -1.81676543, ...,  2.22338438,\n",
       "        -1.70926106,  1.12572825]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6b975db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split out validation dataset for the end\n",
    "X = all_vectors\n",
    "Y= df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f1e0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "992b4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "640b7704",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR.fit(X_train, Y_train)\n",
    "train_result = accuracy_score(lr.predict(X_train), Y_train)\n",
    "    # Test results\n",
    "y_pred=lr.predict(X_test)\n",
    "test_result = accuracy_score(y_pred, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "14b1263e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7320799059929495"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8d09019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"\"\"\n",
    "Today has been quite challenging. I woke up feeling overwhelmed by the tasks ahead. The workload at the office seems never-ending, and there's a constant pressure to meet deadlines. I find myself struggling to balance work and personal life, and it's taking a toll on my mental well-being. During lunch, I couldn't shake off the feeling of anxiety and kept replaying all the things I need to do in my mind.\n",
    "\n",
    "In the afternoon, a meeting with a difficult client added to my stress levels. The pressure to perform well and the fear of making mistakes made my heart race. As the day progressed, I felt the weight of responsibility on my shoulders, and I couldn't stop thinking about how I would manage everything.\n",
    "\n",
    "In the evening, I tried to unwind by going for a walk, but my mind kept racing with thoughts about the challenges I face. Despite my efforts to relax, I still feel a lingering sense of stress and worry. I hope tomorrow will be a better day\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "09812ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = tweets_cleaner(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d3f48c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['today quite challenging woke feeling overwhelmed task ahead workload office seems never ending constant pressure meet deadline find struggling balance work personal life taking toll mental well lunch could shake feeling anxiety kept replaying thing need mind afternoon meeting difficult client added stress level pressure perform well fear making mistake made heart race day progressed felt weight responsibility shoulder could stop thinking would manage everything evening tried unwind going walk mind kept racing thought challenge face despite effort relax still feel lingering sense stress worry hope tomorrow better day']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d35facde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## word-embedding\n",
    "test = pd.np.array([pd.np.array([token.vector for token in nlp(s)]).mean(axis=0) * pd.np.ones((300)) \\\n",
    "                           for s in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea038b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels_pred = lr.predict(test)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8cb03a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a23d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360bfed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
